{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4826e90b",
   "metadata": {},
   "source": [
    "# Loading in Residual Count Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5f009",
   "metadata": {},
   "source": [
    "- each value shows gene expression via RNA sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f0370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584fa8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/RNAseqHarm/ROSMAP_Residualized_counts_(diagnosis-sex-age-death).tsv', delimiter=\"\\t\")\n",
    "df1 = pd.read_csv('data/RNAseqHarm/RNAseq_Harmonization_ROSMAP_combined_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6560030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>510_120515</th>\n",
       "      <th>207_120424</th>\n",
       "      <th>81_120417</th>\n",
       "      <th>649_120529</th>\n",
       "      <th>487_120515</th>\n",
       "      <th>182_120424</th>\n",
       "      <th>193_120424</th>\n",
       "      <th>694_120605</th>\n",
       "      <th>366_120502</th>\n",
       "      <th>...</th>\n",
       "      <th>RISK_73_redo</th>\n",
       "      <th>RISK_74_redo</th>\n",
       "      <th>RISK_78_redo</th>\n",
       "      <th>RISK_8_rerun</th>\n",
       "      <th>RISK_81</th>\n",
       "      <th>RISK_84_redo</th>\n",
       "      <th>RISK_9_rerun</th>\n",
       "      <th>RISK_93</th>\n",
       "      <th>RISK_94</th>\n",
       "      <th>RISK_97</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>0.539745</td>\n",
       "      <td>-0.455791</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>0.927509</td>\n",
       "      <td>-0.821087</td>\n",
       "      <td>-0.654538</td>\n",
       "      <td>-0.614155</td>\n",
       "      <td>0.214444</td>\n",
       "      <td>-0.128681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271698</td>\n",
       "      <td>0.589006</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>-0.857244</td>\n",
       "      <td>-0.226842</td>\n",
       "      <td>0.671701</td>\n",
       "      <td>-0.550307</td>\n",
       "      <td>0.499669</td>\n",
       "      <td>0.351977</td>\n",
       "      <td>-0.035916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>0.177671</td>\n",
       "      <td>0.108173</td>\n",
       "      <td>0.139221</td>\n",
       "      <td>0.224714</td>\n",
       "      <td>-0.057777</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082186</td>\n",
       "      <td>-0.560791</td>\n",
       "      <td>0.040942</td>\n",
       "      <td>-0.284402</td>\n",
       "      <td>0.234696</td>\n",
       "      <td>0.329957</td>\n",
       "      <td>-0.052247</td>\n",
       "      <td>0.204763</td>\n",
       "      <td>0.239964</td>\n",
       "      <td>0.327986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>-0.047954</td>\n",
       "      <td>-0.045705</td>\n",
       "      <td>0.310797</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.166983</td>\n",
       "      <td>0.095107</td>\n",
       "      <td>0.568559</td>\n",
       "      <td>-0.043476</td>\n",
       "      <td>0.037663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162151</td>\n",
       "      <td>-0.083143</td>\n",
       "      <td>0.167290</td>\n",
       "      <td>0.067710</td>\n",
       "      <td>-0.434691</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>-0.189981</td>\n",
       "      <td>0.285131</td>\n",
       "      <td>0.152923</td>\n",
       "      <td>0.158028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>0.405351</td>\n",
       "      <td>0.317188</td>\n",
       "      <td>0.124757</td>\n",
       "      <td>-0.476037</td>\n",
       "      <td>-0.130254</td>\n",
       "      <td>-0.398921</td>\n",
       "      <td>-0.113542</td>\n",
       "      <td>-0.432209</td>\n",
       "      <td>0.244010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164703</td>\n",
       "      <td>0.168071</td>\n",
       "      <td>0.572947</td>\n",
       "      <td>-0.452513</td>\n",
       "      <td>-0.160455</td>\n",
       "      <td>0.092876</td>\n",
       "      <td>-0.273187</td>\n",
       "      <td>0.130140</td>\n",
       "      <td>0.065093</td>\n",
       "      <td>-0.208337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000938</td>\n",
       "      <td>0.463631</td>\n",
       "      <td>0.351991</td>\n",
       "      <td>0.790630</td>\n",
       "      <td>-0.827755</td>\n",
       "      <td>-0.561926</td>\n",
       "      <td>-0.840376</td>\n",
       "      <td>-0.790768</td>\n",
       "      <td>0.498372</td>\n",
       "      <td>0.877291</td>\n",
       "      <td>...</td>\n",
       "      <td>1.758510</td>\n",
       "      <td>2.478327</td>\n",
       "      <td>1.565875</td>\n",
       "      <td>-0.212365</td>\n",
       "      <td>0.676613</td>\n",
       "      <td>0.769315</td>\n",
       "      <td>-0.681266</td>\n",
       "      <td>-0.128797</td>\n",
       "      <td>-0.558991</td>\n",
       "      <td>-0.064519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENSG00000000971</td>\n",
       "      <td>1.249937</td>\n",
       "      <td>-0.146874</td>\n",
       "      <td>0.441918</td>\n",
       "      <td>-0.236982</td>\n",
       "      <td>0.623419</td>\n",
       "      <td>-1.453353</td>\n",
       "      <td>-0.904159</td>\n",
       "      <td>-0.062802</td>\n",
       "      <td>0.237937</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266400</td>\n",
       "      <td>1.484600</td>\n",
       "      <td>1.889318</td>\n",
       "      <td>-0.971408</td>\n",
       "      <td>1.495780</td>\n",
       "      <td>1.123114</td>\n",
       "      <td>-1.491756</td>\n",
       "      <td>-0.138974</td>\n",
       "      <td>-0.451745</td>\n",
       "      <td>-0.009636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENSG00000001036</td>\n",
       "      <td>-0.008286</td>\n",
       "      <td>-0.188718</td>\n",
       "      <td>-0.416688</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>-0.826699</td>\n",
       "      <td>-0.316829</td>\n",
       "      <td>-0.273161</td>\n",
       "      <td>0.091899</td>\n",
       "      <td>-0.208860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561804</td>\n",
       "      <td>0.596316</td>\n",
       "      <td>0.589364</td>\n",
       "      <td>-0.899998</td>\n",
       "      <td>-0.399443</td>\n",
       "      <td>0.224895</td>\n",
       "      <td>-0.513777</td>\n",
       "      <td>0.036233</td>\n",
       "      <td>0.056219</td>\n",
       "      <td>-0.101588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENSG00000001084</td>\n",
       "      <td>-0.147353</td>\n",
       "      <td>-0.176679</td>\n",
       "      <td>-0.414205</td>\n",
       "      <td>0.319511</td>\n",
       "      <td>-1.245328</td>\n",
       "      <td>-0.059856</td>\n",
       "      <td>-0.313164</td>\n",
       "      <td>0.383010</td>\n",
       "      <td>0.182327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361973</td>\n",
       "      <td>-0.279739</td>\n",
       "      <td>0.380595</td>\n",
       "      <td>-0.677527</td>\n",
       "      <td>-0.708829</td>\n",
       "      <td>0.328682</td>\n",
       "      <td>-0.237025</td>\n",
       "      <td>0.114929</td>\n",
       "      <td>0.071345</td>\n",
       "      <td>-0.145800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENSG00000001167</td>\n",
       "      <td>-0.072896</td>\n",
       "      <td>-0.090253</td>\n",
       "      <td>-0.412765</td>\n",
       "      <td>-0.063603</td>\n",
       "      <td>-0.390481</td>\n",
       "      <td>-0.072175</td>\n",
       "      <td>-0.230172</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>-0.051426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191957</td>\n",
       "      <td>0.503687</td>\n",
       "      <td>0.617166</td>\n",
       "      <td>-0.159221</td>\n",
       "      <td>0.087337</td>\n",
       "      <td>0.048982</td>\n",
       "      <td>-0.421458</td>\n",
       "      <td>0.039707</td>\n",
       "      <td>-0.079274</td>\n",
       "      <td>-0.262131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENSG00000001460</td>\n",
       "      <td>0.122713</td>\n",
       "      <td>0.099842</td>\n",
       "      <td>-0.073140</td>\n",
       "      <td>0.338188</td>\n",
       "      <td>0.192039</td>\n",
       "      <td>0.166705</td>\n",
       "      <td>0.367206</td>\n",
       "      <td>-0.160384</td>\n",
       "      <td>0.151252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615839</td>\n",
       "      <td>-0.478519</td>\n",
       "      <td>-0.035306</td>\n",
       "      <td>-0.035690</td>\n",
       "      <td>-0.355101</td>\n",
       "      <td>-0.289961</td>\n",
       "      <td>0.350868</td>\n",
       "      <td>-0.567807</td>\n",
       "      <td>-0.069780</td>\n",
       "      <td>-0.100728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2457 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  510_120515  207_120424  81_120417  649_120529  487_120515  \\\n",
       "0  ENSG00000000003    0.539745   -0.455791   0.029483    0.927509   -0.821087   \n",
       "1  ENSG00000000419    0.032998   -0.096528  -0.003849    0.177671    0.108173   \n",
       "2  ENSG00000000457   -0.047954   -0.045705   0.310797    0.065068    0.166983   \n",
       "3  ENSG00000000460    0.405351    0.317188   0.124757   -0.476037   -0.130254   \n",
       "4  ENSG00000000938    0.463631    0.351991   0.790630   -0.827755   -0.561926   \n",
       "5  ENSG00000000971    1.249937   -0.146874   0.441918   -0.236982    0.623419   \n",
       "6  ENSG00000001036   -0.008286   -0.188718  -0.416688    0.067627   -0.826699   \n",
       "7  ENSG00000001084   -0.147353   -0.176679  -0.414205    0.319511   -1.245328   \n",
       "8  ENSG00000001167   -0.072896   -0.090253  -0.412765   -0.063603   -0.390481   \n",
       "9  ENSG00000001460    0.122713    0.099842  -0.073140    0.338188    0.192039   \n",
       "\n",
       "   182_120424  193_120424  694_120605  366_120502  ...  RISK_73_redo  \\\n",
       "0   -0.654538   -0.614155    0.214444   -0.128681  ...      0.271698   \n",
       "1    0.139221    0.224714   -0.057777    0.004272  ...      0.082186   \n",
       "2    0.095107    0.568559   -0.043476    0.037663  ...     -0.162151   \n",
       "3   -0.398921   -0.113542   -0.432209    0.244010  ...      0.164703   \n",
       "4   -0.840376   -0.790768    0.498372    0.877291  ...      1.758510   \n",
       "5   -1.453353   -0.904159   -0.062802    0.237937  ...      1.266400   \n",
       "6   -0.316829   -0.273161    0.091899   -0.208860  ...      0.561804   \n",
       "7   -0.059856   -0.313164    0.383010    0.182327  ...     -0.361973   \n",
       "8   -0.072175   -0.230172    0.049609   -0.051426  ...      0.191957   \n",
       "9    0.166705    0.367206   -0.160384    0.151252  ...     -0.615839   \n",
       "\n",
       "   RISK_74_redo  RISK_78_redo  RISK_8_rerun   RISK_81  RISK_84_redo  \\\n",
       "0      0.589006      0.067369     -0.857244 -0.226842      0.671701   \n",
       "1     -0.560791      0.040942     -0.284402  0.234696      0.329957   \n",
       "2     -0.083143      0.167290      0.067710 -0.434691      0.474219   \n",
       "3      0.168071      0.572947     -0.452513 -0.160455      0.092876   \n",
       "4      2.478327      1.565875     -0.212365  0.676613      0.769315   \n",
       "5      1.484600      1.889318     -0.971408  1.495780      1.123114   \n",
       "6      0.596316      0.589364     -0.899998 -0.399443      0.224895   \n",
       "7     -0.279739      0.380595     -0.677527 -0.708829      0.328682   \n",
       "8      0.503687      0.617166     -0.159221  0.087337      0.048982   \n",
       "9     -0.478519     -0.035306     -0.035690 -0.355101     -0.289961   \n",
       "\n",
       "   RISK_9_rerun   RISK_93   RISK_94   RISK_97  \n",
       "0     -0.550307  0.499669  0.351977 -0.035916  \n",
       "1     -0.052247  0.204763  0.239964  0.327986  \n",
       "2     -0.189981  0.285131  0.152923  0.158028  \n",
       "3     -0.273187  0.130140  0.065093 -0.208337  \n",
       "4     -0.681266 -0.128797 -0.558991 -0.064519  \n",
       "5     -1.491756 -0.138974 -0.451745 -0.009636  \n",
       "6     -0.513777  0.036233  0.056219 -0.101588  \n",
       "7     -0.237025  0.114929  0.071345 -0.145800  \n",
       "8     -0.421458  0.039707 -0.079274 -0.262131  \n",
       "9      0.350868 -0.567807 -0.069780 -0.100728  \n",
       "\n",
       "[10 rows x 2457 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d5b0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d16d89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18849</th>\n",
       "      <th>18850</th>\n",
       "      <th>18851</th>\n",
       "      <th>18852</th>\n",
       "      <th>18853</th>\n",
       "      <th>18854</th>\n",
       "      <th>18855</th>\n",
       "      <th>18856</th>\n",
       "      <th>18857</th>\n",
       "      <th>18858</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>ENSG00000000938</td>\n",
       "      <td>ENSG00000000971</td>\n",
       "      <td>ENSG00000001036</td>\n",
       "      <td>ENSG00000001084</td>\n",
       "      <td>ENSG00000001167</td>\n",
       "      <td>ENSG00000001460</td>\n",
       "      <td>...</td>\n",
       "      <td>ENSG00000288030</td>\n",
       "      <td>ENSG00000288033</td>\n",
       "      <td>ENSG00000288044</td>\n",
       "      <td>ENSG00000288048</td>\n",
       "      <td>ENSG00000288049</td>\n",
       "      <td>ENSG00000288061</td>\n",
       "      <td>ENSG00000288062</td>\n",
       "      <td>ENSG00000288075</td>\n",
       "      <td>ENSG00000288107</td>\n",
       "      <td>ENSG00000288108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510_120515</th>\n",
       "      <td>0.539745</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>-0.047954</td>\n",
       "      <td>0.405351</td>\n",
       "      <td>0.463631</td>\n",
       "      <td>1.249937</td>\n",
       "      <td>-0.008286</td>\n",
       "      <td>-0.147353</td>\n",
       "      <td>-0.072896</td>\n",
       "      <td>0.122713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>-0.97089</td>\n",
       "      <td>-0.417444</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>-2.033615</td>\n",
       "      <td>-0.125635</td>\n",
       "      <td>-0.642736</td>\n",
       "      <td>-0.286241</td>\n",
       "      <td>-0.127179</td>\n",
       "      <td>-0.438888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207_120424</th>\n",
       "      <td>-0.455791</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.045705</td>\n",
       "      <td>0.317188</td>\n",
       "      <td>0.351991</td>\n",
       "      <td>-0.146874</td>\n",
       "      <td>-0.188718</td>\n",
       "      <td>-0.176679</td>\n",
       "      <td>-0.090253</td>\n",
       "      <td>0.099842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377216</td>\n",
       "      <td>-0.56167</td>\n",
       "      <td>-0.413923</td>\n",
       "      <td>0.312901</td>\n",
       "      <td>2.305215</td>\n",
       "      <td>-0.12738</td>\n",
       "      <td>0.12295</td>\n",
       "      <td>-0.688376</td>\n",
       "      <td>0.606388</td>\n",
       "      <td>1.22845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81_120417</th>\n",
       "      <td>0.029483</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>0.310797</td>\n",
       "      <td>0.124757</td>\n",
       "      <td>0.79063</td>\n",
       "      <td>0.441918</td>\n",
       "      <td>-0.416688</td>\n",
       "      <td>-0.414205</td>\n",
       "      <td>-0.412765</td>\n",
       "      <td>-0.07314</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.062504</td>\n",
       "      <td>0.379108</td>\n",
       "      <td>0.194086</td>\n",
       "      <td>-0.293941</td>\n",
       "      <td>2.348017</td>\n",
       "      <td>0.746473</td>\n",
       "      <td>-0.17943</td>\n",
       "      <td>0.228797</td>\n",
       "      <td>0.148467</td>\n",
       "      <td>0.17962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649_120529</th>\n",
       "      <td>0.927509</td>\n",
       "      <td>0.177671</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>-0.476037</td>\n",
       "      <td>-0.827755</td>\n",
       "      <td>-0.236982</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>0.319511</td>\n",
       "      <td>-0.063603</td>\n",
       "      <td>0.338188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.722717</td>\n",
       "      <td>-0.436119</td>\n",
       "      <td>-0.636299</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>-1.59556</td>\n",
       "      <td>-0.070071</td>\n",
       "      <td>-0.351987</td>\n",
       "      <td>0.280626</td>\n",
       "      <td>-0.149372</td>\n",
       "      <td>0.555551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18859 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                1                2      \\\n",
       "feature     ENSG00000000003  ENSG00000000419  ENSG00000000457   \n",
       "510_120515         0.539745         0.032998        -0.047954   \n",
       "207_120424        -0.455791        -0.096528        -0.045705   \n",
       "81_120417          0.029483        -0.003849         0.310797   \n",
       "649_120529         0.927509         0.177671         0.065068   \n",
       "\n",
       "                      3                4                5      \\\n",
       "feature     ENSG00000000460  ENSG00000000938  ENSG00000000971   \n",
       "510_120515         0.405351         0.463631         1.249937   \n",
       "207_120424         0.317188         0.351991        -0.146874   \n",
       "81_120417          0.124757          0.79063         0.441918   \n",
       "649_120529        -0.476037        -0.827755        -0.236982   \n",
       "\n",
       "                      6                7                8      \\\n",
       "feature     ENSG00000001036  ENSG00000001084  ENSG00000001167   \n",
       "510_120515        -0.008286        -0.147353        -0.072896   \n",
       "207_120424        -0.188718        -0.176679        -0.090253   \n",
       "81_120417         -0.416688        -0.414205        -0.412765   \n",
       "649_120529         0.067627         0.319511        -0.063603   \n",
       "\n",
       "                      9      ...            18849            18850  \\\n",
       "feature     ENSG00000001460  ...  ENSG00000288030  ENSG00000288033   \n",
       "510_120515         0.122713  ...         0.023564         -0.97089   \n",
       "207_120424         0.099842  ...         0.377216         -0.56167   \n",
       "81_120417          -0.07314  ...        -1.062504         0.379108   \n",
       "649_120529         0.338188  ...        -0.722717        -0.436119   \n",
       "\n",
       "                      18851            18852            18853  \\\n",
       "feature     ENSG00000288044  ENSG00000288048  ENSG00000288049   \n",
       "510_120515        -0.417444        -0.001555        -2.033615   \n",
       "207_120424        -0.413923         0.312901         2.305215   \n",
       "81_120417          0.194086        -0.293941         2.348017   \n",
       "649_120529        -0.636299        -0.038195         -1.59556   \n",
       "\n",
       "                      18854            18855            18856  \\\n",
       "feature     ENSG00000288061  ENSG00000288062  ENSG00000288075   \n",
       "510_120515        -0.125635        -0.642736        -0.286241   \n",
       "207_120424         -0.12738          0.12295        -0.688376   \n",
       "81_120417          0.746473         -0.17943         0.228797   \n",
       "649_120529        -0.070071        -0.351987         0.280626   \n",
       "\n",
       "                      18857            18858  \n",
       "feature     ENSG00000288107  ENSG00000288108  \n",
       "510_120515        -0.127179        -0.438888  \n",
       "207_120424         0.606388          1.22845  \n",
       "81_120417          0.148467          0.17962  \n",
       "649_120529        -0.149372         0.555551  \n",
       "\n",
       "[5 rows x 18859 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83574a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2bd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = df2.iloc[0]\n",
    "df2 = df2[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c5c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={'feature':'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36500009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000288030</th>\n",
       "      <th>ENSG00000288033</th>\n",
       "      <th>ENSG00000288044</th>\n",
       "      <th>ENSG00000288048</th>\n",
       "      <th>ENSG00000288049</th>\n",
       "      <th>ENSG00000288061</th>\n",
       "      <th>ENSG00000288062</th>\n",
       "      <th>ENSG00000288075</th>\n",
       "      <th>ENSG00000288107</th>\n",
       "      <th>ENSG00000288108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>510_120515</td>\n",
       "      <td>0.539745</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>-0.047954</td>\n",
       "      <td>0.405351</td>\n",
       "      <td>0.463631</td>\n",
       "      <td>1.249937</td>\n",
       "      <td>-0.008286</td>\n",
       "      <td>-0.147353</td>\n",
       "      <td>-0.072896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023564</td>\n",
       "      <td>-0.97089</td>\n",
       "      <td>-0.417444</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>-2.033615</td>\n",
       "      <td>-0.125635</td>\n",
       "      <td>-0.642736</td>\n",
       "      <td>-0.286241</td>\n",
       "      <td>-0.127179</td>\n",
       "      <td>-0.438888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207_120424</td>\n",
       "      <td>-0.455791</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.045705</td>\n",
       "      <td>0.317188</td>\n",
       "      <td>0.351991</td>\n",
       "      <td>-0.146874</td>\n",
       "      <td>-0.188718</td>\n",
       "      <td>-0.176679</td>\n",
       "      <td>-0.090253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377216</td>\n",
       "      <td>-0.56167</td>\n",
       "      <td>-0.413923</td>\n",
       "      <td>0.312901</td>\n",
       "      <td>2.305215</td>\n",
       "      <td>-0.12738</td>\n",
       "      <td>0.12295</td>\n",
       "      <td>-0.688376</td>\n",
       "      <td>0.606388</td>\n",
       "      <td>1.22845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81_120417</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>0.310797</td>\n",
       "      <td>0.124757</td>\n",
       "      <td>0.79063</td>\n",
       "      <td>0.441918</td>\n",
       "      <td>-0.416688</td>\n",
       "      <td>-0.414205</td>\n",
       "      <td>-0.412765</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.062504</td>\n",
       "      <td>0.379108</td>\n",
       "      <td>0.194086</td>\n",
       "      <td>-0.293941</td>\n",
       "      <td>2.348017</td>\n",
       "      <td>0.746473</td>\n",
       "      <td>-0.17943</td>\n",
       "      <td>0.228797</td>\n",
       "      <td>0.148467</td>\n",
       "      <td>0.17962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>649_120529</td>\n",
       "      <td>0.927509</td>\n",
       "      <td>0.177671</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>-0.476037</td>\n",
       "      <td>-0.827755</td>\n",
       "      <td>-0.236982</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>0.319511</td>\n",
       "      <td>-0.063603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.722717</td>\n",
       "      <td>-0.436119</td>\n",
       "      <td>-0.636299</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>-1.59556</td>\n",
       "      <td>-0.070071</td>\n",
       "      <td>-0.351987</td>\n",
       "      <td>0.280626</td>\n",
       "      <td>-0.149372</td>\n",
       "      <td>0.555551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>487_120515</td>\n",
       "      <td>-0.821087</td>\n",
       "      <td>0.108173</td>\n",
       "      <td>0.166983</td>\n",
       "      <td>-0.130254</td>\n",
       "      <td>-0.561926</td>\n",
       "      <td>0.623419</td>\n",
       "      <td>-0.826699</td>\n",
       "      <td>-1.245328</td>\n",
       "      <td>-0.390481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178033</td>\n",
       "      <td>-0.374037</td>\n",
       "      <td>-0.454228</td>\n",
       "      <td>0.559599</td>\n",
       "      <td>3.03256</td>\n",
       "      <td>-0.072668</td>\n",
       "      <td>0.064121</td>\n",
       "      <td>0.822951</td>\n",
       "      <td>1.840432</td>\n",
       "      <td>0.002488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18860 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0          ID ENSG00000000003 ENSG00000000419 ENSG00000000457 ENSG00000000460  \\\n",
       "1  510_120515        0.539745        0.032998       -0.047954        0.405351   \n",
       "2  207_120424       -0.455791       -0.096528       -0.045705        0.317188   \n",
       "3   81_120417        0.029483       -0.003849        0.310797        0.124757   \n",
       "4  649_120529        0.927509        0.177671        0.065068       -0.476037   \n",
       "5  487_120515       -0.821087        0.108173        0.166983       -0.130254   \n",
       "\n",
       "0 ENSG00000000938 ENSG00000000971 ENSG00000001036 ENSG00000001084  \\\n",
       "1        0.463631        1.249937       -0.008286       -0.147353   \n",
       "2        0.351991       -0.146874       -0.188718       -0.176679   \n",
       "3         0.79063        0.441918       -0.416688       -0.414205   \n",
       "4       -0.827755       -0.236982        0.067627        0.319511   \n",
       "5       -0.561926        0.623419       -0.826699       -1.245328   \n",
       "\n",
       "0 ENSG00000001167  ... ENSG00000288030 ENSG00000288033 ENSG00000288044  \\\n",
       "1       -0.072896  ...        0.023564        -0.97089       -0.417444   \n",
       "2       -0.090253  ...        0.377216        -0.56167       -0.413923   \n",
       "3       -0.412765  ...       -1.062504        0.379108        0.194086   \n",
       "4       -0.063603  ...       -0.722717       -0.436119       -0.636299   \n",
       "5       -0.390481  ...        0.178033       -0.374037       -0.454228   \n",
       "\n",
       "0 ENSG00000288048 ENSG00000288049 ENSG00000288061 ENSG00000288062  \\\n",
       "1       -0.001555       -2.033615       -0.125635       -0.642736   \n",
       "2        0.312901        2.305215        -0.12738         0.12295   \n",
       "3       -0.293941        2.348017        0.746473        -0.17943   \n",
       "4       -0.038195        -1.59556       -0.070071       -0.351987   \n",
       "5        0.559599         3.03256       -0.072668        0.064121   \n",
       "\n",
       "0 ENSG00000288075 ENSG00000288107 ENSG00000288108  \n",
       "1       -0.286241       -0.127179       -0.438888  \n",
       "2       -0.688376        0.606388         1.22845  \n",
       "3        0.228797        0.148467         0.17962  \n",
       "4        0.280626       -0.149372        0.555551  \n",
       "5        0.822951        1.840432        0.002488  \n",
       "\n",
       "[5 rows x 18860 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e718be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2456, 18860)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec903d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         510_120515\n",
       "2         207_120424\n",
       "3          81_120417\n",
       "4         649_120529\n",
       "5         487_120515\n",
       "            ...     \n",
       "2452    RISK_84_redo\n",
       "2453    RISK_9_rerun\n",
       "2454         RISK_93\n",
       "2455         RISK_94\n",
       "2456         RISK_97\n",
       "Name: ID, Length: 2456, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c56983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88_120417     2\n",
       "470_120514    2\n",
       "46_120416     2\n",
       "460_120514    2\n",
       "461_120514    2\n",
       "Name: specimenID, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['specimenID'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "345896e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specimenID</th>\n",
       "      <th>platform</th>\n",
       "      <th>RIN</th>\n",
       "      <th>libraryBatch</th>\n",
       "      <th>sequencingBatch</th>\n",
       "      <th>libraryPrep</th>\n",
       "      <th>libraryPreparationMethod</th>\n",
       "      <th>isStranded</th>\n",
       "      <th>readStrandOrigin</th>\n",
       "      <th>runType</th>\n",
       "      <th>...</th>\n",
       "      <th>age_at_visit_max</th>\n",
       "      <th>age_first_ad_dx</th>\n",
       "      <th>age_death</th>\n",
       "      <th>cts_mmse30_first_ad_dx</th>\n",
       "      <th>cts_mmse30_lv</th>\n",
       "      <th>pmi</th>\n",
       "      <th>braaksc</th>\n",
       "      <th>ceradsc</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>dcfdx_lv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Res_1</td>\n",
       "      <td>IlluminaNovaseq6000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>rRNAdepletion</td>\n",
       "      <td>TruSeq</td>\n",
       "      <td>True</td>\n",
       "      <td>reverse</td>\n",
       "      <td>pairedEnd</td>\n",
       "      <td>...</td>\n",
       "      <td>89.278576317590691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.448323066392888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Res_2</td>\n",
       "      <td>IlluminaNovaseq6000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>rRNAdepletion</td>\n",
       "      <td>TruSeq</td>\n",
       "      <td>True</td>\n",
       "      <td>reverse</td>\n",
       "      <td>pairedEnd</td>\n",
       "      <td>...</td>\n",
       "      <td>87.479808350444898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.723477070499655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Res_4</td>\n",
       "      <td>IlluminaNovaseq6000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>rRNAdepletion</td>\n",
       "      <td>TruSeq</td>\n",
       "      <td>True</td>\n",
       "      <td>reverse</td>\n",
       "      <td>pairedEnd</td>\n",
       "      <td>...</td>\n",
       "      <td>90+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Res_5</td>\n",
       "      <td>IlluminaNovaseq6000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>rRNAdepletion</td>\n",
       "      <td>TruSeq</td>\n",
       "      <td>True</td>\n",
       "      <td>reverse</td>\n",
       "      <td>pairedEnd</td>\n",
       "      <td>...</td>\n",
       "      <td>86.546201232032857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.419575633127991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.583333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Res_6</td>\n",
       "      <td>IlluminaNovaseq6000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>rRNAdepletion</td>\n",
       "      <td>TruSeq</td>\n",
       "      <td>True</td>\n",
       "      <td>reverse</td>\n",
       "      <td>pairedEnd</td>\n",
       "      <td>...</td>\n",
       "      <td>87.750855578370974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.637919233401774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  specimenID             platform  RIN libraryBatch sequencingBatch  \\\n",
       "0      Res_1  IlluminaNovaseq6000  4.2          NaN              15   \n",
       "1      Res_2  IlluminaNovaseq6000  4.0          NaN              15   \n",
       "2      Res_4  IlluminaNovaseq6000  5.3          NaN              15   \n",
       "3      Res_5  IlluminaNovaseq6000  2.7          NaN              15   \n",
       "4      Res_6  IlluminaNovaseq6000  3.7          NaN              15   \n",
       "\n",
       "     libraryPrep libraryPreparationMethod isStranded readStrandOrigin  \\\n",
       "0  rRNAdepletion                   TruSeq       True          reverse   \n",
       "1  rRNAdepletion                   TruSeq       True          reverse   \n",
       "2  rRNAdepletion                   TruSeq       True          reverse   \n",
       "3  rRNAdepletion                   TruSeq       True          reverse   \n",
       "4  rRNAdepletion                   TruSeq       True          reverse   \n",
       "\n",
       "     runType  ...    age_at_visit_max age_first_ad_dx           age_death  \\\n",
       "0  pairedEnd  ...  89.278576317590691             NaN  89.448323066392888   \n",
       "1  pairedEnd  ...  87.479808350444898             NaN  87.723477070499655   \n",
       "2  pairedEnd  ...                 90+             NaN                 90+   \n",
       "3  pairedEnd  ...  86.546201232032857             NaN  87.419575633127991   \n",
       "4  pairedEnd  ...  87.750855578370974             NaN  88.637919233401774   \n",
       "\n",
       "  cts_mmse30_first_ad_dx cts_mmse30_lv        pmi braaksc ceradsc cogdx  \\\n",
       "0                    NaN          29.0   3.750000     4.0     4.0   1.0   \n",
       "1                    NaN          28.0  10.000000     3.0     1.0   1.0   \n",
       "2                    NaN          28.0   6.250000     3.0     4.0   1.0   \n",
       "3                    NaN          30.0   5.583333     4.0     1.0   1.0   \n",
       "4                    NaN          29.0  18.166667     2.0     4.0   1.0   \n",
       "\n",
       "  dcfdx_lv  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      1.0  \n",
       "4      1.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a33a24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = df1[[\n",
    "       'organ', 'tissue', 'BrodmannArea', 'nucleicAcidSource', 'isPostMortem',\n",
    "       'assay', 'exclude', 'excludeReason', 'projid', 'Study', 'msex', 'educ',\n",
    "       'race', 'spanish', 'apoe_genotype', 'age_at_visit_max',\n",
    "       'age_first_ad_dx', 'age_death', 'cts_mmse30_first_ad_dx',\n",
    "       'cts_mmse30_lv', 'pmi', 'braaksc', 'ceradsc', 'cogdx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "392268de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dorsolateral prefrontal cortex    1726\n",
       "Head of caudate nucleus            749\n",
       "posterior cingulate cortex         671\n",
       "temporal cortex                    125\n",
       "frontal cortex                     123\n",
       "Name: tissue, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy['tissue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11f7c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1[['specimenID','cogdx']].copy()\n",
    "df3['HasAlzheimer'] = df3['cogdx'].apply(lambda x: 1 if x in [4, 5] else 0 if x == 1 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dc6e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.merge(df3, df2, left_on='specimenID', right_on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7c20da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492_120515               2\n",
       "567_120521               2\n",
       "560_120517               2\n",
       "561_120517               2\n",
       "562_120517               2\n",
       "                        ..\n",
       "Sample_R5407536-AC       1\n",
       "Sample_R5407536-DLPFC    1\n",
       "Sample_R1073074-AC       1\n",
       "Sample_R1073074-PCC      1\n",
       "RISK_97                  1\n",
       "Name: specimenID, Length: 2456, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx['specimenID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3b8f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dfx.drop_duplicates(subset='specimenID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa61786e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2456, 18863)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5fc3ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492_120515             1\n",
       "Sample_R9253870-PCC    1\n",
       "Sample_R2871843-PCC    1\n",
       "Sample_R8615683-AC     1\n",
       "Sample_R8266864-AC     1\n",
       "                      ..\n",
       "Sample_R1214999-PCC    1\n",
       "Sample_R1214999-AC     1\n",
       "Sample_R3328867-AC     1\n",
       "Sample_R2752714-PCC    1\n",
       "RISK_97                1\n",
       "Name: specimenID, Length: 2456, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx['specimenID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b8b79a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specimenID</th>\n",
       "      <th>cogdx</th>\n",
       "      <th>HasAlzheimer</th>\n",
       "      <th>ID</th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000938</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000288030</th>\n",
       "      <th>ENSG00000288033</th>\n",
       "      <th>ENSG00000288044</th>\n",
       "      <th>ENSG00000288048</th>\n",
       "      <th>ENSG00000288049</th>\n",
       "      <th>ENSG00000288061</th>\n",
       "      <th>ENSG00000288062</th>\n",
       "      <th>ENSG00000288075</th>\n",
       "      <th>ENSG00000288107</th>\n",
       "      <th>ENSG00000288108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492_120515</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>492_120515</td>\n",
       "      <td>-0.432004</td>\n",
       "      <td>-0.062111</td>\n",
       "      <td>0.11296</td>\n",
       "      <td>-0.068069</td>\n",
       "      <td>-0.252136</td>\n",
       "      <td>-1.14896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048852</td>\n",
       "      <td>-0.0733</td>\n",
       "      <td>-0.161494</td>\n",
       "      <td>-0.700259</td>\n",
       "      <td>3.569068</td>\n",
       "      <td>-0.337891</td>\n",
       "      <td>0.142195</td>\n",
       "      <td>0.514537</td>\n",
       "      <td>0.088058</td>\n",
       "      <td>0.132191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_120405</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01_120405</td>\n",
       "      <td>-0.355546</td>\n",
       "      <td>-0.34549</td>\n",
       "      <td>-0.504667</td>\n",
       "      <td>-0.220832</td>\n",
       "      <td>-0.141806</td>\n",
       "      <td>-1.282896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692533</td>\n",
       "      <td>0.098602</td>\n",
       "      <td>0.68737</td>\n",
       "      <td>-0.520883</td>\n",
       "      <td>-0.849084</td>\n",
       "      <td>0.359026</td>\n",
       "      <td>-0.301622</td>\n",
       "      <td>0.568921</td>\n",
       "      <td>1.465695</td>\n",
       "      <td>-1.344327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02_120405</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>02_120405</td>\n",
       "      <td>-0.816047</td>\n",
       "      <td>0.236233</td>\n",
       "      <td>0.276747</td>\n",
       "      <td>0.230103</td>\n",
       "      <td>-0.566289</td>\n",
       "      <td>-0.964827</td>\n",
       "      <td>...</td>\n",
       "      <td>1.331595</td>\n",
       "      <td>-0.303728</td>\n",
       "      <td>0.667944</td>\n",
       "      <td>-1.550739</td>\n",
       "      <td>-1.815264</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.368153</td>\n",
       "      <td>0.245726</td>\n",
       "      <td>-0.158405</td>\n",
       "      <td>-0.002209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>03_120405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>03_120405</td>\n",
       "      <td>-0.958931</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.548188</td>\n",
       "      <td>0.076068</td>\n",
       "      <td>-0.771854</td>\n",
       "      <td>-1.921945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283749</td>\n",
       "      <td>0.430266</td>\n",
       "      <td>0.03365</td>\n",
       "      <td>-0.445345</td>\n",
       "      <td>-1.337655</td>\n",
       "      <td>0.203595</td>\n",
       "      <td>1.017957</td>\n",
       "      <td>-0.14871</td>\n",
       "      <td>1.903356</td>\n",
       "      <td>0.858265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>04_120405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>04_120405</td>\n",
       "      <td>-0.115041</td>\n",
       "      <td>0.200627</td>\n",
       "      <td>0.227565</td>\n",
       "      <td>0.484526</td>\n",
       "      <td>-0.337223</td>\n",
       "      <td>-0.374204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134851</td>\n",
       "      <td>0.174122</td>\n",
       "      <td>-0.195698</td>\n",
       "      <td>-0.652698</td>\n",
       "      <td>-1.696429</td>\n",
       "      <td>0.320636</td>\n",
       "      <td>-0.06094</td>\n",
       "      <td>-0.429307</td>\n",
       "      <td>-0.240233</td>\n",
       "      <td>-0.394856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18863 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   specimenID  cogdx  HasAlzheimer          ID ENSG00000000003  \\\n",
       "0  492_120515    4.0           1.0  492_120515       -0.432004   \n",
       "2   01_120405    6.0           NaN   01_120405       -0.355546   \n",
       "4   02_120405    4.0           1.0   02_120405       -0.816047   \n",
       "6   03_120405    1.0           0.0   03_120405       -0.958931   \n",
       "8   04_120405    1.0           0.0   04_120405       -0.115041   \n",
       "\n",
       "  ENSG00000000419 ENSG00000000457 ENSG00000000460 ENSG00000000938  \\\n",
       "0       -0.062111         0.11296       -0.068069       -0.252136   \n",
       "2        -0.34549       -0.504667       -0.220832       -0.141806   \n",
       "4        0.236233        0.276747        0.230103       -0.566289   \n",
       "6        0.000739        0.548188        0.076068       -0.771854   \n",
       "8        0.200627        0.227565        0.484526       -0.337223   \n",
       "\n",
       "  ENSG00000000971  ... ENSG00000288030 ENSG00000288033 ENSG00000288044  \\\n",
       "0        -1.14896  ...       -0.048852         -0.0733       -0.161494   \n",
       "2       -1.282896  ...       -0.692533        0.098602         0.68737   \n",
       "4       -0.964827  ...        1.331595       -0.303728        0.667944   \n",
       "6       -1.921945  ...        0.283749        0.430266         0.03365   \n",
       "8       -0.374204  ...       -0.134851        0.174122       -0.195698   \n",
       "\n",
       "  ENSG00000288048 ENSG00000288049 ENSG00000288061 ENSG00000288062  \\\n",
       "0       -0.700259        3.569068       -0.337891        0.142195   \n",
       "2       -0.520883       -0.849084        0.359026       -0.301622   \n",
       "4       -1.550739       -1.815264        0.019518        0.368153   \n",
       "6       -0.445345       -1.337655        0.203595        1.017957   \n",
       "8       -0.652698       -1.696429        0.320636        -0.06094   \n",
       "\n",
       "  ENSG00000288075 ENSG00000288107 ENSG00000288108  \n",
       "0        0.514537        0.088058        0.132191  \n",
       "2        0.568921        1.465695       -1.344327  \n",
       "4        0.245726       -0.158405       -0.002209  \n",
       "6        -0.14871        1.903356        0.858265  \n",
       "8       -0.429307       -0.240233       -0.394856  \n",
       "\n",
       "[5 rows x 18863 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbb03da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3400 entries, 0 to 3399\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   specimenID    3400 non-null   object \n",
      " 1   cogdx         3397 non-null   float64\n",
      " 2   HasAlzheimer  2524 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 79.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebee330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = dfx.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3ff657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1818, 18863)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "215c0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5282bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a6f89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import regularizers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63728192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfx.drop(['specimenID', 'cogdx', 'HasAlzheimer', 'ID'], axis=1)  \n",
    "y = dfx['HasAlzheimer']\n",
    "X = X.astype('float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "942d6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05a6d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.62      0.65       177\n",
      "         1.0       0.67      0.73      0.70       187\n",
      "\n",
      "    accuracy                           0.68       364\n",
      "   macro avg       0.68      0.68      0.68       364\n",
      "weighted avg       0.68      0.68      0.68       364\n",
      "\n",
      "[[110  67]\n",
      " [ 50 137]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bda427af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.52%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d4f1051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.84      0.83       177\n",
      "         1.0       0.84      0.83      0.84       187\n",
      "\n",
      "    accuracy                           0.84       364\n",
      "   macro avg       0.84      0.84      0.84       364\n",
      "weighted avg       0.84      0.84      0.84       364\n",
      "\n",
      "[[148  29]\n",
      " [ 31 156]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a8cb4bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.18%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc9c4ab1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.69      0.72       177\n",
      "         1.0       0.73      0.79      0.76       187\n",
      "\n",
      "    accuracy                           0.74       364\n",
      "   macro avg       0.74      0.74      0.74       364\n",
      "weighted avg       0.74      0.74      0.74       364\n",
      "\n",
      "[[122  55]\n",
      " [ 39 148]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad265675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63d82d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 11:23:30.245379: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-07-27 11:23:30.245885: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "\n",
    "model2.add(layers.Dense(512, activation='relu', input_shape=(18859,)))\n",
    "model2.add(layers.Dense(256, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(layers.Dense(128, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6655583",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 11:23:30.778919: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-07-27 11:23:31.035597: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.8796 - acc: 0.5520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 11:23:32.975057: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 37ms/step - loss: 0.8796 - acc: 0.5520 - val_loss: 0.8460 - val_acc: 0.6048\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.7225 - acc: 0.6285 - val_loss: 0.6540 - val_acc: 0.6632\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.6397 - acc: 0.6552 - val_loss: 0.6350 - val_acc: 0.6770\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.5550 - acc: 0.7197 - val_loss: 0.8281 - val_acc: 0.6117\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.5367 - acc: 0.7429 - val_loss: 0.6080 - val_acc: 0.6735\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.4515 - acc: 0.7919 - val_loss: 0.6307 - val_acc: 0.6770\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.3721 - acc: 0.8375 - val_loss: 0.5765 - val_acc: 0.7285\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.3445 - acc: 0.8530 - val_loss: 0.6216 - val_acc: 0.7148\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.2517 - acc: 0.8813 - val_loss: 0.5973 - val_acc: 0.7457\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.2158 - acc: 0.9046 - val_loss: 0.6833 - val_acc: 0.7182\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.1621 - acc: 0.9347 - val_loss: 0.6135 - val_acc: 0.7698\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.1485 - acc: 0.9450 - val_loss: 0.6704 - val_acc: 0.7457\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.1378 - acc: 0.9433 - val_loss: 0.6155 - val_acc: 0.7595\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0929 - acc: 0.9682 - val_loss: 0.8179 - val_acc: 0.6873\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.1282 - acc: 0.9441 - val_loss: 0.7174 - val_acc: 0.7354\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.1301 - acc: 0.9536 - val_loss: 0.6946 - val_acc: 0.7423\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.0894 - acc: 0.9639 - val_loss: 0.9162 - val_acc: 0.7285\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0585 - acc: 0.9819 - val_loss: 0.7729 - val_acc: 0.7423\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0442 - acc: 0.9811 - val_loss: 0.7148 - val_acc: 0.7801\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0388 - acc: 0.9862 - val_loss: 0.8055 - val_acc: 0.7491\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0553 - acc: 0.9802 - val_loss: 0.9873 - val_acc: 0.7354\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0573 - acc: 0.9751 - val_loss: 1.1798 - val_acc: 0.7216\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0479 - acc: 0.9854 - val_loss: 0.8782 - val_acc: 0.7423\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0342 - acc: 0.9862 - val_loss: 0.7655 - val_acc: 0.7732\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0327 - acc: 0.9905 - val_loss: 0.8476 - val_acc: 0.7595\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0360 - acc: 0.9880 - val_loss: 0.8047 - val_acc: 0.7595\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0231 - acc: 0.9940 - val_loss: 0.8003 - val_acc: 0.7629\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.0199 - acc: 0.9940 - val_loss: 0.8631 - val_acc: 0.7423\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.0242 - acc: 0.9923 - val_loss: 0.8700 - val_acc: 0.7560\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.0328 - acc: 0.9914 - val_loss: 0.9307 - val_acc: 0.7526\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.0351 - acc: 0.9914 - val_loss: 0.9677 - val_acc: 0.7388\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0373 - acc: 0.9819 - val_loss: 1.0228 - val_acc: 0.7423\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0156 - acc: 0.9957 - val_loss: 0.8391 - val_acc: 0.7801\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0536 - acc: 0.9854 - val_loss: 0.9741 - val_acc: 0.7491\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0153 - acc: 0.9931 - val_loss: 0.8594 - val_acc: 0.7698\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0273 - acc: 0.9914 - val_loss: 0.9907 - val_acc: 0.7388\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0305 - acc: 0.9931 - val_loss: 0.9478 - val_acc: 0.7629\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0350 - acc: 0.9931 - val_loss: 1.3240 - val_acc: 0.7045\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 0.0618 - acc: 0.9768 - val_loss: 1.0552 - val_acc: 0.7216\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0459 - acc: 0.9785 - val_loss: 1.0926 - val_acc: 0.7388\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0289 - acc: 0.9914 - val_loss: 1.0913 - val_acc: 0.7423\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0370 - acc: 0.9905 - val_loss: 1.0988 - val_acc: 0.7285\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0671 - acc: 0.9768 - val_loss: 1.0149 - val_acc: 0.7457\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0139 - acc: 0.9966 - val_loss: 0.9236 - val_acc: 0.7766\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0233 - acc: 0.9914 - val_loss: 1.0679 - val_acc: 0.7285\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0276 - acc: 0.9914 - val_loss: 0.9973 - val_acc: 0.7354\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.1936 - acc: 0.9475 - val_loss: 1.1911 - val_acc: 0.7079\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0520 - acc: 0.9794 - val_loss: 0.9560 - val_acc: 0.7285\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0725 - acc: 0.9733 - val_loss: 1.1070 - val_acc: 0.7251\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0399 - acc: 0.9845 - val_loss: 1.0887 - val_acc: 0.7354\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0257 - acc: 0.9923 - val_loss: 0.8956 - val_acc: 0.7595\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.9137 - val_acc: 0.7595\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0611 - acc: 0.9845 - val_loss: 1.2029 - val_acc: 0.7216\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 0.0523 - acc: 0.9811 - val_loss: 1.0141 - val_acc: 0.7251\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0239 - acc: 0.9923 - val_loss: 0.9240 - val_acc: 0.7457\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0145 - acc: 0.9957 - val_loss: 0.8899 - val_acc: 0.7698\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0069 - acc: 0.9983 - val_loss: 0.8915 - val_acc: 0.7698\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.8577 - val_acc: 0.7526\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8812 - val_acc: 0.7526\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8743 - val_acc: 0.7560\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 9.7471e-04 - acc: 1.0000 - val_loss: 0.8839 - val_acc: 0.7560\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.8743 - val_acc: 0.7663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8966 - val_acc: 0.7491\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8689 - val_acc: 0.7663\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.8771 - val_acc: 0.7595\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 1.5539 - val_acc: 0.7079\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0588 - acc: 0.9811 - val_loss: 1.0463 - val_acc: 0.7423\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0349 - acc: 0.9888 - val_loss: 1.7486 - val_acc: 0.6942\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0469 - acc: 0.9862 - val_loss: 1.0431 - val_acc: 0.7388\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0228 - acc: 0.9923 - val_loss: 1.0634 - val_acc: 0.7010\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0363 - acc: 0.9880 - val_loss: 1.0191 - val_acc: 0.7320\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0529 - acc: 0.9794 - val_loss: 0.8422 - val_acc: 0.7629\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0186 - acc: 0.9905 - val_loss: 0.9816 - val_acc: 0.7629\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0086 - acc: 0.9983 - val_loss: 0.8799 - val_acc: 0.7388\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 0.0051 - acc: 0.9991 - val_loss: 0.8753 - val_acc: 0.7732\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.8664 - val_acc: 0.7904\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8847 - val_acc: 0.7766\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0145 - acc: 0.9948 - val_loss: 1.0344 - val_acc: 0.7526\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0115 - acc: 0.9983 - val_loss: 0.9960 - val_acc: 0.7698\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0102 - acc: 0.9991 - val_loss: 0.9368 - val_acc: 0.7801\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0041 - acc: 0.9983 - val_loss: 0.9006 - val_acc: 0.7732\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0052 - acc: 0.9974 - val_loss: 1.0012 - val_acc: 0.7732\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 1.1023 - val_acc: 0.7388\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0502 - acc: 0.9837 - val_loss: 1.1117 - val_acc: 0.7388\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0360 - acc: 0.9845 - val_loss: 1.1791 - val_acc: 0.7251\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0305 - acc: 0.9905 - val_loss: 0.9297 - val_acc: 0.7835\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0338 - acc: 0.9862 - val_loss: 1.1445 - val_acc: 0.7526\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0132 - acc: 0.9931 - val_loss: 1.0668 - val_acc: 0.7663\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0153 - acc: 0.9974 - val_loss: 1.1102 - val_acc: 0.7663\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0116 - acc: 0.9966 - val_loss: 1.0953 - val_acc: 0.7526\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0207 - acc: 0.9931 - val_loss: 1.1067 - val_acc: 0.7457\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0262 - acc: 0.9888 - val_loss: 1.1548 - val_acc: 0.7113\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 0.0405 - acc: 0.9837 - val_loss: 1.1752 - val_acc: 0.7148\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0164 - acc: 0.9966 - val_loss: 1.0673 - val_acc: 0.7216\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0087 - acc: 0.9991 - val_loss: 1.0350 - val_acc: 0.7560\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.9743 - val_acc: 0.7698\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9963 - val_acc: 0.7663\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0100 - acc: 0.9948 - val_loss: 1.2490 - val_acc: 0.7560\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0046 - acc: 0.9991 - val_loss: 0.9605 - val_acc: 0.7698\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.9975 - val_acc: 0.7698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f2306820>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "\n",
    "model2.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "409980a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/12 [=>............................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 11:24:26.335510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 18ms/step\n",
      "Accuracy: 78.02%\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model2.predict(X_test)\n",
    "y_pred = np.where(y_pred_proba > 0.5, 1, 0)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c15e2dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.76      0.77       177\n",
      "         1.0       0.78      0.80      0.79       187\n",
      "\n",
      "    accuracy                           0.78       364\n",
      "   macro avg       0.78      0.78      0.78       364\n",
      "weighted avg       0.78      0.78      0.78       364\n",
      "\n",
      "[[135  42]\n",
      " [ 38 149]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2af87c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.52%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model3 = LogisticRegression(max_iter=1000)\n",
    "\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4aa9217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.8379120879120879\n",
      "Best C:  0.1\n"
     ]
    }
   ],
   "source": [
    "# Create a range of values to test for the 'C' parameter\n",
    "c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# Initialize best_score and best_c\n",
    "best_score = 0\n",
    "best_c = None\n",
    "\n",
    "# Perform logistic regression for each value of C\n",
    "for c in c_values:\n",
    "    model = LogisticRegression(C=c, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_c = c\n",
    "\n",
    "print('Best score: ', best_score)\n",
    "print('Best C: ', best_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1acf96c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n",
      "[CV] END ..................C=0.001, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   5.3s\n",
      "[CV] END ..................C=0.001, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END ....................C=0.001, penalty=l2, solver=sag; total time=  16.0s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ..........C=0.001, penalty=elasticnet, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ..........C=0.001, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=liblinear; total time=   0.1s\n",
      "[CV] END ............C=0.001, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ............C=0.001, penalty=elasticnet, solver=sag; total time=   0.1s\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ............C=0.001, penalty=none, solver=newton-cg; total time=   2.5s\n",
      "[CV] END ................C=0.001, penalty=none, solver=lbfgs; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.001, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....................C=0.001, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time=   1.8s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=newton-cg; total time=   6.0s\n",
      "[CV] END ....................C=0.001, penalty=l2, solver=sag; total time=  18.0s\n",
      "[CV] END ............C=0.001, penalty=none, solver=newton-cg; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.001, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   5.2s\n",
      "[CV] END ..................C=0.001, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END ....................C=0.001, penalty=l2, solver=sag; total time=  17.4s\n",
      "[CV] END ............C=0.001, penalty=none, solver=newton-cg; total time=   2.7s\n",
      "[CV] END ................C=0.001, penalty=none, solver=lbfgs; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.001, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   5.0s\n",
      "[CV] END ..................C=0.001, penalty=l2, solver=lbfgs; total time=   3.0s\n",
      "[CV] END ....................C=0.001, penalty=l2, solver=sag; total time=  17.7s\n",
      "[CV] END ............C=0.001, penalty=none, solver=newton-cg; total time=   2.8s\n",
      "[CV] END ................C=0.001, penalty=none, solver=lbfgs; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.001, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   5.2s\n",
      "[CV] END ..................C=0.001, penalty=l2, solver=lbfgs; total time=   2.8s\n",
      "[CV] END ....................C=0.001, penalty=l2, solver=sag; total time=  16.2s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ..........C=0.001, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........C=0.001, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..........C=0.001, penalty=elasticnet, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ......C=0.001, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............C=0.001, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ............C=0.001, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ............C=0.001, penalty=elasticnet, solver=sag; total time=   0.1s\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ............C=0.001, penalty=none, solver=newton-cg; total time=   2.6s\n",
      "[CV] END ................C=0.001, penalty=none, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ................C=0.001, penalty=none, solver=lbfgs; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............C=0.001, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..................C=0.001, penalty=none, solver=sag; total time= 1.9min\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   1.8s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   1.1s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...........C=0.01, penalty=elasticnet, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.1s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.1s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.1s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.1s\n",
      "[CV] END .......C=0.01, penalty=elasticnet, solver=liblinear; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END .............C=0.01, penalty=elasticnet, solver=sag; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=elasticnet, solver=sag; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=elasticnet, solver=sag; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=elasticnet, solver=sag; total time=   0.1s\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   2.2s\n",
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   2.2s\n",
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   2.2s\n",
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   2.5s\n",
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   1.1s\n",
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.001, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ....................C=0.001, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time=   2.4s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=newton-cg; total time=   5.0s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=liblinear; total time=   3.1s\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time=  24.6s\n",
      "[CV] END .................C=0.001, penalty=none, solver=saga; total time= 2.1min\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time= 1.2min\n",
      "[CV] END ...................C=0.01, penalty=none, solver=sag; total time= 2.0min\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   1.3s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ......................C=0.1, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.9min\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............C=0.1, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ........C=0.1, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=elasticnet, solver=sag; total time=   0.1s\n",
      "[CV] END ..............C=0.1, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=newton-cg; total time=   2.5s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=newton-cg; total time=   2.4s\n",
      "[CV] END ..................C=0.1, penalty=none, solver=lbfgs; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............C=0.001, penalty=l1, solver=newton-cg; total time=   0.2s\n",
      "[CV] END ....................C=0.001, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time=   1.9s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=newton-cg; total time=   5.0s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=liblinear; total time=   3.2s\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time=  28.2s\n",
      "[CV] END .................C=0.001, penalty=none, solver=saga; total time= 2.1min\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   3.5s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   3.8s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   5.4s\n",
      "[CV] END .....................C=0.01, penalty=l2, solver=sag; total time=  30.1s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=  43.3s\n",
      "[CV] END ..................C=0.01, penalty=none, solver=saga; total time= 2.2min\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   5.8s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   5.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   6.2s\n",
      "[CV] END ......................C=0.1, penalty=l2, solver=sag; total time= 1.1min\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 2.0min\n",
      "[CV] END ...................C=0.1, penalty=none, solver=saga; total time= 2.2min\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............C=0.001, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END ............C=0.001, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=0.001, penalty=none, solver=sag; total time= 1.9min\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=0.01, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   2.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.9s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time= 1.3min\n",
      "[CV] END .............C=0.01, penalty=none, solver=newton-cg; total time=   2.3s\n",
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   1.1s\n",
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   1.0s\n",
      "[CV] END .................C=0.01, penalty=none, solver=lbfgs; total time=   1.0s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END .............C=0.01, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END ...................C=0.01, penalty=none, solver=sag; total time= 2.0min\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   1.7s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   1.3s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.9min\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=newton-cg; total time=   2.5s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=newton-cg; total time=   2.6s\n",
      "[CV] END ..................C=0.1, penalty=none, solver=lbfgs; total time=   1.2s\n",
      "[CV] END ..............C=0.1, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, penalty=none, solver=sag; total time= 1.9min\n",
      "[CV] END ......................C=1, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   2.1s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 3.5min\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ................C=1, penalty=none, solver=newton-cg; total time=   2.3s\n",
      "[CV] END ................C=1, penalty=none, solver=newton-cg; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.001, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   5.0s\n",
      "[CV] END ..................C=0.001, penalty=l2, solver=lbfgs; total time=   2.7s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=liblinear; total time=   3.3s\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time=  27.1s\n",
      "[CV] END .................C=0.001, penalty=none, solver=saga; total time= 2.1min\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   4.3s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   3.5s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   5.8s\n",
      "[CV] END .....................C=0.01, penalty=l2, solver=sag; total time=  33.5s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=  41.1s\n",
      "[CV] END ..................C=0.01, penalty=none, solver=saga; total time= 2.2min\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   3.4s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   3.8s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   4.8s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   7.4s\n",
      "[CV] END ......................C=0.1, penalty=l2, solver=sag; total time= 1.1min\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END ...................C=0.1, penalty=none, solver=saga; total time= 2.2min\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   3.8s\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   4.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   5.9s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   8.7s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 2.2min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.0s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END .......................C=10, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 4.6min\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.1s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   2.3s\n",
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................C=0.001, penalty=l1, solver=lbfgs; total time=   0.2s\n",
      "[CV] END ....................C=0.001, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time=   2.1s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=newton-cg; total time=   5.1s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=liblinear; total time=   3.3s\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time=  27.3s\n",
      "[CV] END .................C=0.001, penalty=none, solver=saga; total time= 2.1min\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=newton-cg; total time=   3.1s\n",
      "[CV] END ...................C=0.01, penalty=l2, solver=lbfgs; total time=   4.1s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   6.4s\n",
      "[CV] END .....................C=0.01, penalty=l2, solver=sag; total time=  27.8s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=  44.5s\n",
      "[CV] END ..................C=0.01, penalty=none, solver=saga; total time= 2.2min\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   3.6s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=newton-cg; total time=   4.1s\n",
      "[CV] END ....................C=0.1, penalty=l2, solver=lbfgs; total time=   5.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   7.4s\n",
      "[CV] END ......................C=0.1, penalty=l2, solver=sag; total time= 1.1min\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.9min\n",
      "[CV] END ...................C=0.1, penalty=none, solver=saga; total time= 2.2min\n",
      "[CV] END ..................C=1, penalty=l2, solver=newton-cg; total time=   4.1s\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   5.9s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   8.9s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 2.2min\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .....................C=10, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   2.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 4.6min\n",
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   2.4s\n",
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   1.1s\n",
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   1.1s\n",
      "[CV] END ............C=0.001, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..................C=0.001, penalty=none, solver=sag; total time= 2.2min\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END ..................C=0.01, penalty=none, solver=saga; total time= 2.3min\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   6.3s\n",
      "[CV] END ......................C=0.1, penalty=l2, solver=sag; total time= 1.3min\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END ...................C=0.1, penalty=none, solver=saga; total time= 2.2min\n",
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   5.8s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   8.6s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 2.2min\n",
      "[CV] END .....................C=1, penalty=none, solver=saga; total time= 2.2min\n",
      "[CV] END .....................C=10, penalty=l2, solver=lbfgs; total time=   7.1s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   8.6s\n",
      "[CV] END .......................C=10, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 2.1min\n",
      "[CV] END ....................C=10, penalty=none, solver=saga; total time= 2.1min\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   3.5s\n",
      "[CV] END ................C=100, penalty=l2, solver=newton-cg; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, penalty=l2, solver=lbfgs; total time=   6.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   7.8s\n",
      "[CV] END ......................C=100, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END ..............C=100, penalty=none, solver=newton-cg; total time=   2.5s\n",
      "[CV] END ..................C=100, penalty=none, solver=lbfgs; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, penalty=l2, solver=lbfgs; total time=   5.7s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   8.5s\n",
      "[CV] END ........................C=1, penalty=l2, solver=sag; total time= 2.0min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 2.2min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 4.6min\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.1s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=newton-cg; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............C=10, penalty=elasticnet, solver=lbfgs; total time=   0.1s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END .........C=10, penalty=elasticnet, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=elasticnet, solver=sag; total time=   0.1s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.1s\n",
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   2.4s\n",
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   1.1s\n",
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   1.1s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=none, solver=sag; total time= 1.9min\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=newton-cg; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   1.9s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   1.5s\n",
      "[CV] END ......................C=100, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ......................C=100, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ......................C=100, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ......................C=100, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END ......................C=100, penalty=l1, solver=sag; total time=   0.1s\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 3.4min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 2.3min\n",
      "[CV] END ...................C=100, penalty=none, solver=saga; total time= 2.1min\n",
      "[CV] END ...............C=1000, penalty=l2, solver=newton-cg; total time=   2.9s\n",
      "[CV] END ...............C=1000, penalty=l2, solver=newton-cg; total time=   2.7s\n",
      "[CV] END ...............C=1000, penalty=l2, solver=newton-cg; total time=   3.4s\n",
      "[CV] END ...................C=1000, penalty=l2, solver=lbfgs; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=0.1, penalty=none, solver=sag; total time= 2.2min\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 3.5min\n",
      "[CV] END ......................C=1, penalty=none, solver=sag; total time= 1.9min\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   1.8s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 4.6min\n",
      "[CV] END ...............C=10, penalty=none, solver=newton-cg; total time=   2.5s\n",
      "[CV] END ...................C=10, penalty=none, solver=lbfgs; total time=   1.1s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=10, penalty=none, solver=liblinear; total time=   0.1s\n",
      "[CV] END .....................C=10, penalty=none, solver=sag; total time= 1.9min\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=100, penalty=l1, solver=lbfgs; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   1.8s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   1.4s\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 3.4min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 2.2min\n",
      "[CV] END ...................C=100, penalty=none, solver=saga; total time= 2.1min\n",
      "[CV] END ...............C=1000, penalty=l2, solver=newton-cg; total time=   3.2s\n",
      "[CV] END ...............C=1000, penalty=l2, solver=newton-cg; total time=   3.7s\n",
      "[CV] END ...................C=1000, penalty=l2, solver=lbfgs; total time=   4.3s\n",
      "[CV] END ...................C=1000, penalty=l2, solver=lbfgs; total time=   4.0s\n",
      "[CV] END ...................C=1000, penalty=l2, solver=lbfgs; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "315 fits failed out of a total of 700.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1178, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 73, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/tooters/lib/python3.8/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.45185686        nan 0.54814314 0.80328712\n",
      " 0.8039744  0.80259983 0.80397677 0.80259746        nan        nan\n",
      "        nan        nan        nan 0.83699253 0.81703282        nan\n",
      " 0.83285934 0.83010783        nan        nan 0.64649129        nan\n",
      " 0.65335229 0.82528973 0.82528973 0.83285934 0.82941818 0.83010546\n",
      "        nan        nan        nan        nan        nan 0.83699253\n",
      " 0.81703282        nan 0.83492357 0.83148477        nan        nan\n",
      " 0.77165304        nan 0.77509658 0.83216732 0.83216732 0.83492831\n",
      " 0.8314824  0.83079275        nan        nan        nan        nan\n",
      "        nan 0.83699253 0.81703282        nan 0.83355137 0.83010783\n",
      "        nan        nan 0.76751274        nan 0.80946084 0.83423154\n",
      " 0.83423154 0.83836237 0.83285934 0.83148477        nan        nan\n",
      "        nan        nan        nan 0.83699253 0.81703282        nan\n",
      " 0.83286171 0.83079512        nan        nan 0.77784098        nan\n",
      " 0.83079038 0.83491646 0.83491646 0.83973931 0.83217443 0.8314824\n",
      "        nan        nan        nan        nan        nan 0.83699253\n",
      " 0.81703282        nan 0.83286171 0.83217206        nan        nan\n",
      " 0.81289963        nan 0.83079512 0.83698305 0.83698305 0.83767508\n",
      " 0.83423865 0.82941818        nan        nan        nan        nan\n",
      "        nan 0.83699253 0.81703282        nan 0.83217443 0.83217206\n",
      "        nan        nan 0.82528262        nan 0.83079512 0.83560611\n",
      " 0.83629103 0.83905202 0.83286171 0.83217206        nan        nan\n",
      "        nan        nan        nan 0.83699253 0.81703282        nan\n",
      " 0.83217443 0.83010783]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Check the best parameters found by GridSearchCV\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b4c3561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "47d5a281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.34%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.87      0.84       177\n",
      "         1.0       0.87      0.82      0.84       187\n",
      "\n",
      "    accuracy                           0.84       364\n",
      "   macro avg       0.84      0.84      0.84       364\n",
      "weighted avg       0.84      0.84      0.84       364\n",
      "\n",
      "[[154  23]\n",
      " [ 34 153]]\n"
     ]
    }
   ],
   "source": [
    "# Fit a new model using the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "best_model = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], solver=best_params['solver'], max_iter=1000)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# If you want to print a classification report, showing precision, recall and f1-score, you can do this:\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# If you want to print the confusion matrix, you can do this:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "948abba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENSG00000261701    0.301210\n",
      "ENSG00000055732    0.295909\n",
      "ENSG00000115602    0.275936\n",
      "ENSG00000167244    0.267051\n",
      "ENSG00000251410    0.266328\n",
      "ENSG00000225178    0.261380\n",
      "ENSG00000221882    0.260847\n",
      "ENSG00000132744    0.257552\n",
      "ENSG00000287978    0.253564\n",
      "ENSG00000154608    0.247586\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names (proteins) from your data\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Get the coefficients from the model\n",
    "coefficients = best_model.coef_[0]\n",
    "\n",
    "# Create a pandas Series for easy manipulation\n",
    "coef_series = pd.Series(coefficients, index=feature_names)\n",
    "\n",
    "\n",
    "# Get the absolute values to consider the magnitude of the coefficients\n",
    "abs_coefs = coef_series.abs()\n",
    "\n",
    "# Sort the features by the absolute values of their coefficients in descending order\n",
    "sorted_features = abs_coefs.sort_values(ascending=False)\n",
    "\n",
    "# Print the top n features\n",
    "n = 10  # change this to the number of top features you want to print\n",
    "print(sorted_features[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73f70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tooters",
   "language": "python",
   "name": "tooters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
